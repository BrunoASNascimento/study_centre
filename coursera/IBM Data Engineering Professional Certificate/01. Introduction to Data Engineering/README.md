# Introduction to Data Engineering

## Modern Data Ecosystem and role of Data Engineering

### Welcome to Introduction to Data Engineering

Welcome to this introductory course on Data Engineering, the first in a series of courses designed to prepare you for a career as a Junior Data Engineer.
Data is growing at an unprecedented rate. And so are the ways in which data is being tapped by businesses, industries, institutions, and governments, all over the world, for making decisions that guide their future and the future of the people they serve. How much value we can derive from data really depends on just two things – the accuracy of data and the efficiency with which we’re able to access the data we need, when we need it. And that, in a nutshell, is the job of a Data Engineer. And the opportunity is huge. Dice Tech Job Report of 2020 lists data engineering as the fastest-growing tech occupation with year-over-year growth of 50%.
This course is for you if you want to become a data engineer. You may have a background in engineering or computer science, you may be a graduate from a non-related stream, or you may be a non-graduate who loves coding – you can start your journey on this path by taking this course. You may even be a data professional who is excited about engineering, or a working professional with a technical role, in whichever capacity – this course will help you upskill and gain an opportunity in this field. This course introduces you to the core concepts, ecosystem, and life cycle of data engineering. You will learn about data, data repositories, data pipelines, data integration platforms, and big data. You will learn about the architecture of a data platform, the design considerations for a data store, how to extract, transform, and clean data to make it ready for analytics, and the principles of data security, privacy, and compliance regulations.
You will hear from a panel of subject matter experts and practitioners sharing their knowledge and advising you on possible pathways that can help you become a data engineer. Hi, I'm Rav Ahuja. I'm a computer engineer by education, a data engineer by training, and I currently lead the content and strategy team for IBM Skills Network. My name is Amber Crooks and I have been a data professional for about 20 years now. I started my career with databases straight out of college with IBM. I was a DB2 database administrator. Currently, I am a lead database engineer for an organization that does a lot of work with DevOps. I am Ramesh Sannareddy. I am the CEO of a company called Mongo Factory. At Mongo Factory, we provide data engineering consulting. My name is Xiao Yang. I'm a data engineer at Coursera. Hi, my name is Ragu Cherukuru. I work as a lead database administrator for a large retailer out here in the Midwest. Today we are going to talk about data engineering. We are very excited to bring this course to you. Congratulations on choosing to be on this journey and good luck!

### Modern Data Ecosystem

To quote a Forbes 2020 report on data in the coming decade, “The constant increase in data processing speeds and bandwidth, the nonstop invention of new tools for creating, sharing, and consuming data, and the steady addition of new data creators and consumers around the world, ensure that data growth continues unabated. Data begets more data in a constant virtuous cycle.” A modern data ecosystem includes a whole network of interconnected, independent, and continually evolving entities. It includes data that has to be integrated from disparate sources; different types of analysis and skills to generate insights; active stakeholders to collaborate and act on insights generated; and tools, applications, and infrastructure to store, process, and disseminate data as required. Let’s start with the data sources. Data is available in a variety of structured and unstructured datasets, residing in text, images, videos, clickstreams, user conversations, social media platforms, the Internet of Things (or IoT) devices, real-time events that stream data, legacy databases, and data sourced from professional data providers and agencies. The sources have never before been so diverse and dynamic. When you’re working with so many different sources of data, the first step is to pull a copy of the data from the original sources into a data repository. At this stage, you’re only looking at acquiring the data you need—working with data formats, sources, and interfaces through which this data can be pulled in. Reliability, security, and integrity of the data being acquired are some of the challenges you work through at this stage.
Once the raw data is in a common place, it needs to get organized, cleaned up, and optimized for access by end-users. The data will also need to conform to compliances and standards enforced in the organization. For example, conforming to guidelines that regulate the storage and use of personal data such as health, biometrics, or household data in the case of IoT devices. Adhering to master data tables within the organization, to ensure standardization of master data across all applications and systems of an organization, is another example. The key challenges at this stage could involve data management and working with data repositories that provide high availability, flexibility, accessibility, and security.
Finally, we have our business stakeholders, applications, programmers, analysts, and data science use cases all pulling this data from the enterprise data repository. The key challenges at this stage could include the interfaces, APIs, and applications that can get this data to the end-users in line with their specific needs. For example, Data Analysts may need the raw data to work with, business stakeholders may need reports and dashboards, applications may need custom APIs to pull this data.
It’s important to note the influence of some of the new and emerging technologies that are shaping today’s data ecosystem and its possibilities. For example, Cloud Computing, Machine Learning, and Big Data, to name a few. Thanks to cloud technologies, every enterprise today has access to limitless storage, high-performance computing, open source technologies, machine learning technologies, and the latest tools and libraries. Data Scientists are creating predictive models by training machine learning algorithms on past data. Also, Big Data—Today we’re dealing with datasets that are so massive and so varied that traditional tools and analysis methods are no longer adequate, paving the way for new tools and techniques and also new knowledge and insights. We’ll learn more about Big Data and its influence in shaping business decisions further along in this course.

### Key Players in the Data Ecosystem

Today, organizations that are using data to uncover opportunities and are applying that knowledge to differentiate themselves are the ones leading into the future. Whether looking for patterns in financial transactions to detect fraud, using recommendation engines to drive conversion, mining social media posts for customer voice, or brands personalizing their offers based on customer behavior analysis, business leaders realize that data holds the key to competitive advantage. To get value from data, you need a vast number of skillsets and people playing different roles. In this video we’re going to look at the role Data Engineers, Data Analysts, Data Scientists, Business Analysts, and Business Intelligence (or BI) Analysts play in helping organizations tap into vast amounts of data and turn them into actionable insights. It all starts with a Data Engineer. Data Engineers are people who develop and maintain data architectures and make data available for business operations and analysis. Data Engineers work within the data ecosystem to extract, integrate, and organize data from disparate sources; clean, transform, and prepare data; design, store, and manage data in data repositories. They enable data to be accessible in formats and systems that the various business applications, as well as stakeholders like Data Analysts and Data Scientists, can utilize. A Data Engineer must have good knowledge of programming, sound knowledge of systems and technology architectures, and in-depth understanding of relational databases and non-relational datastores. Now let’s look at the role of a Data Analyst. In short, a Data Analyst translates data and numbers into plain language, so organizations can make decisions. Data Analysts inspect, and clean data for deriving insights; identify correlations, find patterns, and apply statistical methods to analyze and mine data; and visualize data to interpret and present the findings of data analysis. Analysts are the people who answer questions such as “Are the users’ search experiences generally good or bad with the search functionality on our site” or “What is the popular perception of people regarding our rebranding initiatives” or “Is there a correlation between sales of one product and another." Data Analysts require good knowledge of spreadsheets, writing queries, and using statistical tools to create charts and dashboards. Modern data analysts also need to have some programming skills. They need strong analytical and story-telling skills. And now let’s look at the role Data Scientists play in this ecosystem. Data Scientists analyze data for actionable insights and build Machine Learning or Deep Learning models that train on past data to create predictive models. Data Scientists are people who answer questions such as “How many new social media followers am I likely to get next month?” or “What percentage of my customers am I likely to lose to competition in the next quarter” or “Is this financial transaction unusual for this customer?”. Data Scientists require knowledge of Mathematics, Statistics, and a fair understanding of programming languages, databases, and building data models. They also need to have domain knowledge. Then we also have business Analysts and BI Analysts. Business Analystsleverage the work of Data Analysts and Data Scientists to look at possible implications for their business and the actions they need to take or recommend. BI Analysts do the same, except their focus is on the market forces and external influences that shape their business. They provide business intelligence solutions by organizing and monitoring data on different business functions and exploring that data to extract insights and actionables that improve business performance. To summarize in simple terms, Data Engineering converts raw data into usable data. Data Analytics uses this data to generate insights. Data Scientists use Data Analytics and Data Engineering to predict the future using data from the past. Business Analysts and Business Intelligence Analysts use these insights and predictions to drive decisions that benefit and grow their business. Interestingly, it’s not uncommon for data professionals to start their career in one of the data roles and transition to another role within the data ecosystem by supplementing their skills.

### What is Data Engineering?

In this video, we will further explore the scope of data engineering within the modern data ecosystem. In the simplest possible terms, the field of Data Engineering concerns itself with the mechanics for the flow and access of data. And its goal is to make quality data available for fact-finding and data-driven decision making. As data has grown, so has the field of data engineering. From data being available in a single database that was relatively easier to manage—the world of data has grown to include wide-ranging sources, structures, and types of data. The field of Data Engineering concerns itself with the tasks of collecting source data includes extracting, integrating, and organizing data from disparate sources. To collect required data, you need to: Develop tools, workflows, and processes that help you acquire data from multiple sources. Design, build, and maintain scalable data architecture to store data. Data could be stored in databases, data warehouses, data lakes, or any other type of data repository. Processing data includes cleaning, transforming, and preparing data so that it is usable. For this, you need to: Implement and maintain distributed systems for large-scale processing of data. Design pipelines for the extraction, transformation, and loading of data into data repositories. Design or implement solutions for validating and safeguarding quality, privacy, and security of data. Optimize tools, systems, and workflows for performance, reliability, and scalability. Ensure data meets all regulatory and compliance guidelines. Storing data for reliable and easy availability of data. For this, you need to: Architect or implement data stores for the storage of processed data. Ensure systems are scalable, keeping in mind the evolving nature of data and business needs. Ensure tools and systems are in place that take care of data privacy, security, compliance, monitoring, backup, and recovery. Making data available to users securely. This includes the use of: APIs, services, and programs that retrieve data on defined parameters for use by end-users. Interfaces and dashboards that present data to users so they can derive insights from the data. Ensure the right measures and checks and balances are in place to keep data secure and provide rights-based access to users. It is important to mention that data engineering is a team sport. No one person is expected to have all the knowledge, skills, and specializations required for the wide-ranging tasks covered within the scope of data engineering. For example, to architect any data management system, be it for collating source data or storing processed analysis-ready data, you need to have the skills of an architect. To ensure data stores are available and optimized for use, you need to have expertise in databases. Similarly, proficiency in database tools, programming languages, and distributed systems all come under data engineering, but they may require different skill sets. Also, not all teams and organizations need to set up an end-to-end data engineering practice. There are tools, applications, and solutions available in the market, both on-premise and cloud-based, that can be evaluated for individual needs. In this video, we learned how data engineering works to provide a robust and scalable structure to make quality data available for decision-making. More than any other data profession, data engineering is about the tools and technologies involved in data manipulation. But it is also about understanding the complexities of data and how it is ultimately leveraged for fact-finding and decision-making.

### Viewpoints: Defining Data Engineering

In this video, we will listen to several data professionals talk about how they define data engineering and how it differs from data analytics and data science.
Data engineering is the tasks of designing, building, maintaining data infrastructures and platforms. These data infrastructures can include databases, Big Data repositories, as well as data pipelines for transforming and moving data between these systems. So, a Data Engineer is someone who performs these tasks of developing and optimizing data systems and make data available for analysis. Whereas a Data Analyst is someone who analyzes data in these systems to report and derive insights.
And a Data Scientist takes this even further by performing deeper analysis on the data and developing predictive models to solve more complex data problems. As data engineers, we are kind of the plumbers of data. We make sure that the data is highly available. We make sure that the data is consistent. We make sure that the data is secure. And we make sure that the data is recoverable. We don't spend as much time playing with the data or analyzing the data, or actually using the data, as we do making sure it's ready for others to do those jobs. Alot of times, data science and data analytics will make use of the data that we that we store. It's also a scenario where we work closely with other data professionals to make sure that the data matches their needs and is available in a way that actually helps them. Data engineering is all about designing, maintaining, and optimizing systems that will help enterprises and companies make the most of their data. When we get into specifics, it's all about choosing the right databases, the right storage systems, the right cloud architectures or cloud platforms, so that when we put together all these things, the data flow inside an organization is seamless and data can be delivered to whoever needs it at whatever time, with minimal effort and as soon as possible. In an ideal organization with the best data engineering processes, anybody can get access to any data that he or she is authorized to in a split second of time.
Now, if you talk about data analysts and data scientists, their work can be thought of as an upstream work. That is, after the job of a data engineer finishes and the data is made available, then data analysts and data scientists can make use of that data to work out their analysis and come up with their predictions. Data engineers extract and collect raw data from multiple sources, transform them and store them in table forms. While other scientists or analysts, they perform analysis on top of the data that's prepared by data engineering and try to engage business insights from those data. You can think of data engineering as a precursor to the data analysis and data science. Data engineers act as enablers and make the data projects of data analysts and data scientists materialize into reality. For example, they can assist the data analysts and data scientists with picking the right databases and tools, and by building the required data pipelines to help with their data needs, and build their reports, and perform statistical analysis.

### Viewpoints: Evolution of Data Engineering

In this video, we will listen to several data professionals talk about how data engineering has evolved over the past couple of decades.
Compared to two decades back, the data engineering ecospace, or landscape, is a totally different one. It's almost unrecognizable compared to what it was two decades back.
If you look at today's scenario, this sheer quantity of data that we handle today was unthinkable two decades back. We also handle with a variety of data and data formats, which probably didn't even exist the two decades back. And two decades back we were not talking about the concept of NoSQL databases, but today we work with a variety of NoSQL databases. And two decades back, Big Data was unheard of, whereas today it is pretty much stable, to many enterprises and organisations. One of the major difference that I see between, you know, before two decades and now, is the expectations from data engineering. They have grown a lot. Today, when a data engineer is given a job. The turn around time is a lot less. Earlier we could take days to come back with a solution, but today the expectation is that OK, we come back with a solution within hours.
And today, you cannot run a complete data engineering
service without the use of automation tools. So, you need a lot of automation tools to make sure that we deliver the data engineering service
to the organization.
So I started off in this field almost 25 years ago and there's been a significant evolution in technology in general, but specifically as data and data technologies and systems are concerned. So for example, with cloud computing
data infrastructure is now available as a service. So data engineer, today, needs to do a lot less from scratch. They can spend more time on doing things that matter and less time on setting up and managing these systems. So when I started off in data engineering, it primarily involved using relational databases and data warehouses. Now there's a lot of NoSQL databases and other types of data repositories.
Another major evolution has been around Big Data. And data engineers today need to know how to work with several different Big Data systems and pipelines.
And while there are still specializations, today I think a data engineer needs to know about a greater variety of tools and data systems, and how they can be effectively used for solving different types of data problems. So over the past couple of decades the way that we handle data has changed very significantly. When I started, it was a very hierarchical approach. There was somebody at the top, an Architect and Enterprise Architect, a Data Architect. People who decided how we were going to store data within an organization. Usually there were a couple or three supported platforms and we stuck to those. That was well defined for us. And over the last 20 years, it's been a very gradual transition from that to a situation where it's much more often that the way data is stored comes to us from a developer. A developer wants it stored in a particular way, a developer has specific requirements. So it's interesting to have the requirements coming from a different direction and that changes our role a little bit. So instead of making sure that we are really great on those two or three platforms that were previously defined for us, what we have to do now is we have to take these varying sets of requirements and needs from developers, and work with those developers to make sure that the choices they're making are appropriate for data operations for the long term use of data and storage of data in a secure and reliable way. So it's more of a conversation in how things happen and it's much more of a learning expedition for the data engineer to go out and figure out what's the best way to do this new thing that the developers need. What's the best way for me to do this and still have that reliable, highly available, secure data platform that is what the organization really means? Data engineering evolved tremendously in the past couple of decades. When I started 15 years ago as a database administrator, data engineering was not that hot topic. There were data engineers, but it's a full-on
very hot requirement these days. So the reason for this is
it's basically the evolution of different kinds of data sources. For example, now we have Internet of Things related data. All these sensors related information being fed into these various kinds of data sources.
And API feeds from Twitter or weather APIs, you name it. And everything interconnected. As a result of the need for a variety of data sources evolved. For example, you have relational databases for a long time, for maybe four or five decades. Now you have column stores, wide column stores, like Cassandra or HBase and key-value pair databases,
Hadoop for Big Data,
document stores like MongoDB or Coachbase. So as a data engineer, you need to be familiar with all these kinds of data sources, with the evolution of data sources, and the variety of the data. The data engineering role evolved significantly over the past couple of decades. I have only works in data engineering for two years, so I can only share what I have learned or observed during the past two years. I think traditionally data engineering focuses a lot on database management, ETL pipelines, and
data visualization.
While in recent years I have seen a lot of more and more demand for data engineering to understand this distributed computing and DevOps, and to implement machine learning models and so on.
## Responsibilities and Skillsets of a Data Engineer
### Responsibilities and Skillsets of a Data Engineer
In this video, we will learn about the responsibilities and skillsets of a Data Engineer. The overarching responsibility of a data engineer is to provide analytics-ready data to data consumers. Data is analytics-ready when it is accurate, reliable, complies to regulations it is governed by, and is accessible to consumers when they need it. At a broad level, Data Engineers: Extract, organize, and integrate data from disparate sources, Prepare data for analysis and reporting by transforming and cleansing it, Design and manage data pipelines that encompass the journey of data from source to destination systems, Setup and manage the infrastructure required for the ingestion, processing, and storage of data. This can include data platforms, data stores for aggregating source data, distributed systems for large-scale processing of data, and data repositories for storage and dissemination of analysis-ready data. Next, we’ll learn about some of the technical, functional, and soft skills that you may need as a Data Engineer. Let’s begin with the technical skills. These include: Knowledge of working with operating systems such as UNIX, Linux, and Windows, including commonly used administrative tools, system utilities and commands. Knowledge of infrastructure components, such as virtual machines, networking, and application services, such as load balancing and application performance monitoring. Also, cloud-based services such as those offered by Amazon, Google, IBM, and Microsoft. Experience of working with databases and data warehouses, which include: RDBMSes such as IBM DB2, MySQL, Oracle Database, and PostgreSQL. NoSQL databases such as Redis, MongoDB, Cassandra, and Neo4J. Data warehouses such as Oracle Exadata, IBM Db2 Warehouse on Cloud, IBM Netezza Performance Server, and Amazon RedShift. A high-level of proficiency working with data pipelines. Popular data pipeline solutions include Apache Beam, AirFlow, and DataFLow. Experience of working with ETL tools such as IBM Infosphere Information Server, AWS Glue, and Improvado. Proficiency in languages for querying, manipulating, and processing data. This includes: Query languages for accessing and manipulating data in a database, such as SQL for relational databases and SQL-like query languages for NoSQL databases. Programming languages such as Python, R, and Java. Shell and Scripting languages, such as Unix/Linux Shell and PowerShell. Familiarity with Big Data processing tools such as Hadoop, Hive, and Spark. The data engineering process involves using several different tools and technologies. Having a working knowledge of comparable technologies can help you evaluate the trade-offs between different tools and make appropriate recommendations. Data engineering is at the intersection of software engineering and data science. In addition to the tools and technologies that data engineers use on a daily basis, they also need to have a keen understanding of how data scientists, analysts, and business users leverage analysis-ready data. Some of the functional skills that will serve you as a Data Engineer, include: The ability to convert business requirements into technical specifications. The ability to work with the complete software development lifecycle which includes ideation, architecture, design, prototyping, testing, deployment, and monitoring. An understanding of data’s potential application in business. And an understanding of the risks of poor data management which essentially covers data quality, privacy, security, and compliance. Data engineering is a team sport. You could have multiple data engineers bringing in their specialization to collaborate on a project, closely interacting with the data consumers—which includes the analysts, data scientists, business users, and other technical teams. Interpersonal skills, teamwork, and collaboration, therefore, are essential for data engineers. As a data engineer, you need to be able to communicate effectively with both technical and non-technical stakeholders in a manner that a clear understanding can be established. In this video, you learned about some of the responsibilities and skillsets of a data engineer. Data engineering requires a broad set of skillsets. No one data engineer can possibly master each one of these skills, which means you essentially need to select one or more specialization areas, but have a good understanding of all areas so that you can make more informed decisions. Your skills will grow over time with experience, the areas you choose to focus on, and the time you invest in upskilling yourself.